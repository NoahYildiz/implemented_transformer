# Transformer Training Requirements
# Core dependencies for the transformer implementation

# PyTorch (install with appropriate CUDA version)
torch>=2.0.0
torchvision>=0.15.0

# Data handling
datasets>=2.14.0
tokenizers>=0.13.0

# Experiment tracking
wandb>=0.15.0

# Evaluation metrics
evaluate>=0.4.0
sacrebleu>=2.3.0

# Configuration
pyyaml>=6.0

# Progress bars
tqdm>=4.65.0

# Numerical operations
numpy>=1.24.0

# Dependencies for torchvision / accelerate / matplotlib
pillow>=8.0,!=8.3.*
psutil>=5.9.0
python-dateutil>=2.7

# Optional: HuggingFace Transformers (for tokenizer wrapper)
transformers>=4.30.0
accelerate>=0.20.0

# Optional: plotting (matplotlib and its dependencies)
matplotlib>=3.7.0
contourpy>=1.0.1
cycler>=0.10
fonttools>=4.22.0
kiwisolver>=1.3.1
pyparsing>=2.3.1

# Optional: scikit-learn for additional metrics
scikit-learn>=1.2.0

# Development dependencies
pytest>=7.3.0
pytest-cov>=4.1.0
black>=23.3.0
isort>=5.12.0
flake8>=6.0.0
